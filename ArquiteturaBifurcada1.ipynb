{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArquiteturaBifurcada1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zN_VwnW98i4JDbhSLQ6HnJhbx4fX5YsQ",
      "authorship_tag": "ABX9TyPJ/8Qze4q7DKEqhWReAUSa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42ccc1ff43d54075adebd3759b3f118b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2fddcfc3502f4049992431ef8603edac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f3e5f5d315245c399ee679d2b0de050",
              "IPY_MODEL_61d484ab66b9471586a568fd9da02a3c",
              "IPY_MODEL_0b5b7126ab604a2f836331382daef527"
            ]
          }
        },
        "2fddcfc3502f4049992431ef8603edac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f3e5f5d315245c399ee679d2b0de050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_addcd02189c74e4787702b29a9f402b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b8fb590497a448c8d638dd00211d7c4"
          }
        },
        "61d484ab66b9471586a568fd9da02a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1be3d011882c458ca2cd8daa8e74d551",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46830571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46830571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da295de8e75d4bafae98aebf198c4e0c"
          }
        },
        "0b5b7126ab604a2f836331382daef527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_af06ac5331f240ffb71707331d8d2d18",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 135MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f29af5550244457adfd832ceaa08a2f"
          }
        },
        "addcd02189c74e4787702b29a9f402b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b8fb590497a448c8d638dd00211d7c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1be3d011882c458ca2cd8daa8e74d551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da295de8e75d4bafae98aebf198c4e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af06ac5331f240ffb71707331d8d2d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f29af5550244457adfd832ceaa08a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julianolm/my-torch-utils/blob/main/ArquiteturaBifurcada1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI3DcuFTQk2S"
      },
      "source": [
        "Primeira versao da arquitetura bifurcada\n",
        "\n",
        "Resnet18 (pretreinada/fixa) + LBCNNResnet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FjM2qRzj_ng"
      },
      "source": [
        "import torch, torchvision, torch.nn as nn\n",
        "from torch import Tensor\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yn1qXRzkzxP"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8xPAF8as_ZD"
      },
      "source": [
        "## Resnet part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "42ccc1ff43d54075adebd3759b3f118b",
            "2fddcfc3502f4049992431ef8603edac",
            "5f3e5f5d315245c399ee679d2b0de050",
            "61d484ab66b9471586a568fd9da02a3c",
            "0b5b7126ab604a2f836331382daef527",
            "addcd02189c74e4787702b29a9f402b1",
            "3b8fb590497a448c8d638dd00211d7c4",
            "1be3d011882c458ca2cd8daa8e74d551",
            "da295de8e75d4bafae98aebf198c4e0c",
            "af06ac5331f240ffb71707331d8d2d18",
            "3f29af5550244457adfd832ceaa08a2f"
          ]
        },
        "id": "G6VS-j_HlALO",
        "outputId": "a4c16a6d-c5ab-4b61-aac1-52114fdc77b2"
      },
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self, pretrained: bool = True):\n",
        "        super().__init__()\n",
        "        self.net = torchvision.models.resnet18(pretrained=pretrained)\n",
        "        for _, param in self.net.named_parameters():\n",
        "            param.requires_grad = False\n",
        "        self.net.avgpool = Identity()\n",
        "        self.net.fc = Identity()\n",
        "    \n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.net.conv1(x)\n",
        "        x = self.net.bn1(x)\n",
        "        x = self.net.relu(x)\n",
        "        x = self.net.maxpool(x)\n",
        "\n",
        "        x = self.net.layer1(x)\n",
        "        x = self.net.layer2(x)\n",
        "        x = self.net.layer3(x)\n",
        "        x = self.net.layer4(x)\n",
        "\n",
        "        x = self.net.avgpool(x)\n",
        "        # x = torch.flatten(x, 1)\n",
        "        x = self.net.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "resnet = Resnet()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42ccc1ff43d54075adebd3759b3f118b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQZtqd6RU9fl"
      },
      "source": [
        "x = torch.randn(128, 3, 224, 224)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAO529EfpIM8",
        "outputId": "1f016f5a-ca50-4942-9cf6-4547890b8bd3"
      },
      "source": [
        "resnet(x).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDmQr1z9rUHM"
      },
      "source": [
        "output was supposed to be (128, 512, 7, 7)\n",
        "\n",
        "hitnt: 7x7x512 = 25088"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBNmjEOfqG4T",
        "outputId": "adbed674-454b-49d1-943d-0c965f2c8161"
      },
      "source": [
        "torchvision.models.resnet18()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moHPN5uBqmIq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h56BtuR1tC_h"
      },
      "source": [
        "## LBCNN part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGScX3ixtETL"
      },
      "source": [
        "from drive.MyDrive.IC import juefei_lbcnn_resnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcFYSgazUW_L"
      },
      "source": [
        "class LBCResnet(nn.Module):\n",
        "    def __init__(self, pretrained: bool = False) -> None:\n",
        "        super().__init__()\n",
        "        self.net = juefei_lbcnn_resnet.resnet18(pretrained=pretrained)\n",
        "        self.net.avgpool = Identity()\n",
        "        self.net.fc = Identity()\n",
        "    \n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.net.conv1(x)\n",
        "        x = self.net.bn1(x)\n",
        "        x = self.net.relu(x)\n",
        "        x = self.net.maxpool(x)\n",
        "\n",
        "        x = self.net.layer1(x)\n",
        "        x = self.net.layer2(x)\n",
        "        x = self.net.layer3(x)\n",
        "        x = self.net.layer4(x)\n",
        "\n",
        "        x = self.net.avgpool(x)\n",
        "        # x = torch.flatten(x, 1)\n",
        "        x = self.net.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "lbc_resnet = LBCResnet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiIzTBVxU4qi",
        "outputId": "57e8085e-1baf-4b57-cffa-16992e4161e2"
      },
      "source": [
        "lbc_resnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LBCResnet(\n",
              "  (net): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): LBConvBN(\n",
              "          (random_binary_conv): RandomBinaryConv()\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (fc): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (avgpool): Identity()\n",
              "    (fc): Identity()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77vyQajzVbcA",
        "outputId": "ea285c33-a1aa-4986-9a7e-d8fffc0491cc"
      },
      "source": [
        "lbc_resnet(x).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cns6QQT5Vgkc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njr5W5ZpYiaq"
      },
      "source": [
        "##Mixed Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG0RMJhXYjpE"
      },
      "source": [
        "class MixedNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MixedNet, self).__init__()\n",
        "        self.res = Resnet(pretrained=True)\n",
        "        self.lbc = LBCResnet(pretrained=False)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "        self.fc = nn.Linear(512, 10)\n",
        "\n",
        "    \n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.res(x) + self.lbc(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYkZYOmWZx7h"
      },
      "source": [
        "mixed_net = MixedNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-CWY8Tytv4j",
        "outputId": "82d49088-181f-4d54-a731-8353a3b68a3a"
      },
      "source": [
        "mixed_net(x).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jDDl9E5tvtk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eARXfWlpt5MR"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IDYvNTwtvrZ"
      },
      "source": [
        "import time\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# import os\n",
        "import sys\n",
        "# import time\n",
        "# import math\n",
        "\n",
        "# import torch.nn.init as init\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "# import torchvision\n",
        "# from torchvision import datasets, transforms\n",
        "\n",
        "# import argparse\n",
        "\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zvn3bRavEy_"
      },
      "source": [
        "# !unzip \"/content/drive/MyDrive/fmd.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZfEY8cw3rjf"
      },
      "source": [
        "'''Some helper functions for PyTorch, including:\n",
        "    - get_mean_and_std: calculate the mean and std value of dataset.\n",
        "    - msr_init: net parameter initialization.\n",
        "    - progress_bar: progress bar mimic xlua.progress.\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "def get_mean_and_std(dataset):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    print('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:,i,:,:].mean()\n",
        "            std[i] += inputs[:,i,:,:].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std\n",
        "\n",
        "def init_params(net):\n",
        "    '''Init layer parameters.'''\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            init.kaiming_normal(m.weight, mode='fan_out')\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            init.constant(m.weight, 1)\n",
        "            init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            init.normal(m.weight, std=1e-3)\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "\n",
        "\n",
        "# _, term_width = os.popen('stty size', 'r').read().split()\n",
        "# term_width = int(term_width)\n",
        "term_width = 32\n",
        "\n",
        "TOTAL_BAR_LENGTH = 65.\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICh6oTM53rg3",
        "outputId": "17cff784-b3d4-41e2-8889-e2b37b840384"
      },
      "source": [
        "# parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
        "# parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "# parser.add_argument('--resume', '-r', action='store_true',\n",
        "#                     help='resume from checkpoint')\n",
        "# args = parser.parse_args()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "transform_test = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "data_dir = '/content/image'\n",
        "dataset_train = datasets.ImageFolder(data_dir, transform=transform_train)\n",
        "dataset_test = datasets.ImageFolder(data_dir, transform=transform_test)\n",
        "\n",
        "dataset_sizes = len(dataset_train)\n",
        "classes = dataset_train.classes\n",
        "print(classes)\n",
        "\n",
        "def divide_treino_validacao(train_rate=0.9):\n",
        "    \"\"\"\n",
        "    As classes estao divididas no dataset da seguinte forma: (0-99: classe 1),\n",
        "                                                             (100-199: classe 2),\n",
        "                                                             ...\n",
        "                                                             (900-999: classe 10)\n",
        "    \n",
        "    Temos que dividir os indices aleatoriamente para treino e validacao, mas lembrando que as \n",
        "    proporcoes definidas para treino e validacao devem ser respeitadas entre cada uma das classes.\n",
        "    \"\"\"\n",
        "    train_indices = []\n",
        "    val_indices = []\n",
        "    for i in range(10):\n",
        "        ind = np.arange(i*100, (i+1)*100)\n",
        "        ind = np.random.permutation(ind)\n",
        "        \n",
        "        frontier = int(len(ind)*train_rate)\n",
        "        ind_t = ind[0:frontier]\n",
        "        ind_v = ind[frontier:len(ind)]\n",
        "\n",
        "        train_indices += ind_t.tolist()\n",
        "        val_indices += ind_v.tolist()\n",
        "\n",
        "    return (train_indices, val_indices)\n",
        "        \n",
        "train_indices, val_indices = divide_treino_validacao(0.5)\n",
        "\n",
        "trainset = torch.utils.data.Subset(dataset_train, train_indices)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torch.utils.data.Subset(dataset_test, val_indices)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "# trainset = torchvision.datasets.CIFAR10(\n",
        "#     root='./data', train=True, download=True, transform=transform_train)\n",
        "# trainloader = torch.utils.data.DataLoader(\n",
        "#     trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "# testset = torchvision.datasets.CIFAR10(\n",
        "#     root='./data', train=False, download=True, transform=transform_test)\n",
        "# testloader = torch.utils.data.DataLoader(\n",
        "#     testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Model\n",
        "print('==> Building model..')\n",
        "# net = VGG('VGG19')\n",
        "# net = resnet18(pretrained=False)\n",
        "net = MixedNet()\n",
        "# net = PreActResNet18()\n",
        "# net = GoogLeNet()\n",
        "# net = DenseNet121()\n",
        "# net = ResNeXt29_2x64d()\n",
        "# net = MobileNet()\n",
        "# net = MobileNetV2()\n",
        "# net = DPN92()\n",
        "# net = ShuffleNetG2()\n",
        "# net = SENet18()\n",
        "# net = ShuffleNetV2(1)\n",
        "# net = EfficientNetB0()\n",
        "# net = RegNetX_200MF()\n",
        "# net = SimpleDLA()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "# if args.resume:\n",
        "#     # Load checkpoint.\n",
        "#     print('==> Resuming from checkpoint..')\n",
        "#     assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "#     checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "#     net.load_state_dict(checkpoint['net'])\n",
        "#     best_acc = checkpoint['acc']\n",
        "#     start_epoch = checkpoint['epoch']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc, state\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc >= best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        # if not os.path.isdir('checkpoint'):\n",
        "        #     os.mkdir('checkpoint')\n",
        "        # torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "\n",
        "\n",
        "# for epoch in range(start_epoch, start_epoch+2):\n",
        "#     train(epoch)\n",
        "#     test(epoch)\n",
        "#     scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric', 'foliage', 'glass', 'leather', 'metal', 'paper', 'plastic', 'stone', 'water', 'wood']\n",
            "==> Building model..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhE71_GxiIFb",
        "outputId": "e137afdd-96dc-4795-f1e2-668472ea59a2"
      },
      "source": [
        "#Avaliando na FMD a LBCNN sem estar treinada\n",
        "test(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [===============================================================>.]  Step: 462ms | Tot: 55s119ms | Loss: 14092022024220346.000 | Acc: 8.200% (41/500)\b\b 63/63 \n",
            "Saving..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRzB8nWvABi0",
        "outputId": "45339a0a-115b-412c-a36f-198f2fb994f2"
      },
      "source": [
        "for epoch in range(start_epoch, start_epoch+50):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [===============================================================>.]  Step: 883ms | Tot: 1m43s | Loss: 2.949 | Acc: 16.600% (83/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 468ms | Tot: 55s404ms | Loss: 1.885 | Acc: 32.200% (161/500)\b\b 63/63 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [===============================================================>.]  Step: 851ms | Tot: 1m41s | Loss: 1.915 | Acc: 38.200% (191/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 463ms | Tot: 55s310ms | Loss: 1.656 | Acc: 46.800% (234/500)\b\b 63/63 \n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [===============================================================>.]  Step: 908ms | Tot: 1m43s | Loss: 1.648 | Acc: 44.200% (221/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 477ms | Tot: 56s645ms | Loss: 1.304 | Acc: 61.000% (305/500)\b\b 63/63 \n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [===============================================================>.]  Step: 871ms | Tot: 1m41s | Loss: 1.339 | Acc: 56.600% (283/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 452ms | Tot: 55s391ms | Loss: 1.222 | Acc: 62.600% (313/500)\b\b 63/63 \n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [===============================================================>.]  Step: 850ms | Tot: 1m40s | Loss: 1.270 | Acc: 55.600% (278/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 461ms | Tot: 54s241ms | Loss: 1.118 | Acc: 66.000% (330/500)\b\b 63/63 \n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            " [===============================================================>.]  Step: 867ms | Tot: 1m39s | Loss: 1.383 | Acc: 54.600% (273/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 453ms | Tot: 53s468ms | Loss: 1.670 | Acc: 57.600% (288/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 6\n",
            " [===============================================================>.]  Step: 861ms | Tot: 1m38s | Loss: 1.347 | Acc: 57.400% (287/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 457ms | Tot: 54s417ms | Loss: 1.105 | Acc: 64.400% (322/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 7\n",
            " [===============================================================>.]  Step: 876ms | Tot: 1m41s | Loss: 1.158 | Acc: 60.400% (302/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 508ms | Tot: 56s454ms | Loss: 1.356 | Acc: 62.200% (311/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 8\n",
            " [===============================================================>.]  Step: 892ms | Tot: 1m44s | Loss: 1.113 | Acc: 62.400% (312/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 469ms | Tot: 56s934ms | Loss: 0.940 | Acc: 70.400% (352/500)\b\b 63/63 \n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            " [===============================================================>.]  Step: 885ms | Tot: 1m43s | Loss: 1.067 | Acc: 64.800% (324/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 488ms | Tot: 56s587ms | Loss: 1.371 | Acc: 61.000% (305/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 10\n",
            " [===============================================================>.]  Step: 891ms | Tot: 1m42s | Loss: 1.245 | Acc: 60.800% (304/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 460ms | Tot: 56s138ms | Loss: 0.874 | Acc: 72.000% (360/500)\b\b 63/63 \n",
            "Saving..\n",
            "\n",
            "Epoch: 11\n",
            " [===============================================================>.]  Step: 863ms | Tot: 1m40s | Loss: 1.049 | Acc: 66.600% (333/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 446ms | Tot: 54s958ms | Loss: 0.924 | Acc: 71.200% (356/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 12\n",
            " [===============================================================>.]  Step: 865ms | Tot: 1m40s | Loss: 0.943 | Acc: 68.800% (344/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 509ms | Tot: 55s363ms | Loss: 0.921 | Acc: 70.400% (352/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 13\n",
            " [===============================================================>.]  Step: 876ms | Tot: 1m41s | Loss: 0.896 | Acc: 69.600% (348/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 465ms | Tot: 55s680ms | Loss: 0.877 | Acc: 72.200% (361/500)\b\b 63/63 \n",
            "Saving..\n",
            "\n",
            "Epoch: 14\n",
            " [===============================================================>.]  Step: 873ms | Tot: 1m41s | Loss: 1.018 | Acc: 66.400% (332/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 466ms | Tot: 55s111ms | Loss: 0.940 | Acc: 70.400% (352/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 15\n",
            " [===============================================================>.]  Step: 866ms | Tot: 1m41s | Loss: 0.971 | Acc: 67.000% (335/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 488ms | Tot: 56s875ms | Loss: 1.213 | Acc: 65.000% (325/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 16\n",
            " [===============================================================>.]  Step: 906ms | Tot: 1m44s | Loss: 0.975 | Acc: 67.600% (338/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 485ms | Tot: 57s814ms | Loss: 1.069 | Acc: 69.000% (345/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 17\n",
            " [===============================================================>.]  Step: 932ms | Tot: 1m44s | Loss: 0.957 | Acc: 70.800% (354/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 469ms | Tot: 57s942ms | Loss: 0.855 | Acc: 74.000% (370/500)\b\b 63/63 \n",
            "Saving..\n",
            "\n",
            "Epoch: 18\n",
            " [===============================================================>.]  Step: 907ms | Tot: 1m44s | Loss: 0.853 | Acc: 72.200% (361/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 477ms | Tot: 57s308ms | Loss: 0.989 | Acc: 69.800% (349/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 19\n",
            " [===============================================================>.]  Step: 897ms | Tot: 1m42s | Loss: 0.952 | Acc: 70.200% (351/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 455ms | Tot: 55s45ms | Loss: 1.077 | Acc: 70.600% (353/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 20\n",
            " [===============================================================>.]  Step: 857ms | Tot: 1m40s | Loss: 0.916 | Acc: 69.600% (348/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 444ms | Tot: 55s86ms | Loss: 1.290 | Acc: 68.800% (344/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 21\n",
            " [===============================================================>.]  Step: 855ms | Tot: 1m40s | Loss: 1.060 | Acc: 66.800% (334/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 463ms | Tot: 55s165ms | Loss: 1.185 | Acc: 68.400% (342/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 22\n",
            " [===============================================================>.]  Step: 867ms | Tot: 1m41s | Loss: 0.960 | Acc: 72.000% (360/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 462ms | Tot: 55s864ms | Loss: 0.943 | Acc: 69.200% (346/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 23\n",
            " [===============================================================>.]  Step: 895ms | Tot: 1m40s | Loss: 1.156 | Acc: 63.800% (319/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 483ms | Tot: 56s148ms | Loss: 1.081 | Acc: 71.200% (356/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 24\n",
            " [===============================================================>.]  Step: 879ms | Tot: 1m41s | Loss: 1.066 | Acc: 66.400% (332/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 469ms | Tot: 55s898ms | Loss: 1.160 | Acc: 69.000% (345/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 25\n",
            " [===============================================================>.]  Step: 865ms | Tot: 1m40s | Loss: 0.840 | Acc: 71.400% (357/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 489ms | Tot: 54s769ms | Loss: 1.072 | Acc: 70.000% (350/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 26\n",
            " [===============================================================>.]  Step: 892ms | Tot: 1m40s | Loss: 0.835 | Acc: 73.000% (365/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 466ms | Tot: 55s586ms | Loss: 1.072 | Acc: 72.000% (360/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 27\n",
            " [===============================================================>.]  Step: 907ms | Tot: 1m41s | Loss: 0.954 | Acc: 70.000% (350/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 480ms | Tot: 54s897ms | Loss: 0.986 | Acc: 70.600% (353/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 28\n",
            " [===============================================================>.]  Step: 847ms | Tot: 1m40s | Loss: 0.814 | Acc: 73.000% (365/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 474ms | Tot: 55s775ms | Loss: 1.131 | Acc: 69.600% (348/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 29\n",
            " [===============================================================>.]  Step: 881ms | Tot: 1m40s | Loss: 0.859 | Acc: 72.400% (362/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 475ms | Tot: 54s868ms | Loss: 1.430 | Acc: 67.600% (338/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 30\n",
            " [===============================================================>.]  Step: 903ms | Tot: 1m41s | Loss: 0.783 | Acc: 73.200% (366/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 476ms | Tot: 55s725ms | Loss: 0.957 | Acc: 72.200% (361/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 31\n",
            " [===============================================================>.]  Step: 889ms | Tot: 1m42s | Loss: 0.838 | Acc: 72.200% (361/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 456ms | Tot: 55s261ms | Loss: 1.048 | Acc: 70.800% (354/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 32\n",
            " [===============================================================>.]  Step: 857ms | Tot: 1m40s | Loss: 0.937 | Acc: 70.800% (354/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 455ms | Tot: 54s224ms | Loss: 1.251 | Acc: 69.200% (346/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 33\n",
            " [===============================================================>.]  Step: 887ms | Tot: 1m40s | Loss: 0.862 | Acc: 73.000% (365/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 472ms | Tot: 55s435ms | Loss: 1.048 | Acc: 71.000% (355/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 34\n",
            " [===============================================================>.]  Step: 864ms | Tot: 1m42s | Loss: 0.777 | Acc: 73.200% (366/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 442ms | Tot: 55s475ms | Loss: 1.406 | Acc: 64.000% (320/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 35\n",
            " [===============================================================>.]  Step: 903ms | Tot: 1m42s | Loss: 0.835 | Acc: 73.400% (367/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 471ms | Tot: 56s471ms | Loss: 1.444 | Acc: 69.800% (349/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 36\n",
            " [===============================================================>.]  Step: 871ms | Tot: 1m41s | Loss: 0.721 | Acc: 75.600% (378/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 481ms | Tot: 54s413ms | Loss: 1.121 | Acc: 71.400% (357/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 37\n",
            " [===============================================================>.]  Step: 920ms | Tot: 1m43s | Loss: 0.792 | Acc: 75.200% (376/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 478ms | Tot: 55s763ms | Loss: 1.006 | Acc: 70.800% (354/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 38\n",
            " [===============================================================>.]  Step: 886ms | Tot: 1m42s | Loss: 0.709 | Acc: 76.000% (380/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 460ms | Tot: 56s180ms | Loss: 1.072 | Acc: 70.600% (353/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 39\n",
            " [===============================================================>.]  Step: 900ms | Tot: 1m43s | Loss: 0.842 | Acc: 72.800% (364/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 446ms | Tot: 55s828ms | Loss: 0.966 | Acc: 71.200% (356/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 40\n",
            " [===============================================================>.]  Step: 888ms | Tot: 1m40s | Loss: 0.812 | Acc: 73.000% (365/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 474ms | Tot: 55s177ms | Loss: 1.305 | Acc: 68.600% (343/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 41\n",
            " [===============================================================>.]  Step: 873ms | Tot: 1m40s | Loss: 0.671 | Acc: 79.000% (395/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 455ms | Tot: 53s952ms | Loss: 1.079 | Acc: 68.000% (340/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 42\n",
            " [===============================================================>.]  Step: 856ms | Tot: 1m40s | Loss: 0.783 | Acc: 75.000% (375/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 452ms | Tot: 55s75ms | Loss: 1.075 | Acc: 69.600% (348/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 43\n",
            " [===============================================================>.]  Step: 877ms | Tot: 1m38s | Loss: 0.755 | Acc: 74.200% (371/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 471ms | Tot: 54s643ms | Loss: 1.238 | Acc: 67.400% (337/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 44\n",
            " [===============================================================>.]  Step: 941ms | Tot: 1m44s | Loss: 0.762 | Acc: 73.200% (366/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 497ms | Tot: 58s622ms | Loss: 1.347 | Acc: 67.400% (337/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 45\n",
            " [===============================================================>.]  Step: 910ms | Tot: 1m41s | Loss: 0.739 | Acc: 77.000% (385/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 462ms | Tot: 57s96ms | Loss: 1.094 | Acc: 70.400% (352/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 46\n",
            " [===============================================================>.]  Step: 921ms | Tot: 1m42s | Loss: 0.610 | Acc: 79.400% (397/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 452ms | Tot: 54s802ms | Loss: 1.003 | Acc: 71.600% (358/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 47\n",
            " [===============================================================>.]  Step: 961ms | Tot: 1m43s | Loss: 0.629 | Acc: 77.800% (389/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 461ms | Tot: 57s196ms | Loss: 1.328 | Acc: 65.200% (326/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 48\n",
            " [===============================================================>.]  Step: 855ms | Tot: 1m40s | Loss: 0.811 | Acc: 72.400% (362/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 457ms | Tot: 54s291ms | Loss: 1.402 | Acc: 68.200% (341/500)\b\b 63/63 \n",
            "\n",
            "Epoch: 49\n",
            " [===============================================================>.]  Step: 869ms | Tot: 1m40s | Loss: 0.747 | Acc: 74.800% (374/500)\b\b 63/63 \n",
            " [===============================================================>.]  Step: 446ms | Tot: 54s557ms | Loss: 1.323 | Acc: 67.400% (337/500)\b\b 63/63 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4tshb0QN2uf",
        "outputId": "5f6de45c-19e4-49a0-d9cd-55e2db239f0b"
      },
      "source": [
        "state['acc'], state['epoch']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74.0, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRLpmaO4N_vD"
      },
      "source": [
        "# torch.save(state['net'], '/content/drive/MyDrive/IC/ArquiteturaBifurcada1.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wah-zVJAOPsT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}